{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, let us explore the dataset that is given for this competition.\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "This dataset contains an anonymized set of variables that describe different Mercedes cars. The ground truth is labeled 'y' and represents the time (in seconds) that the car took to pass testing. \n",
    "\n",
    "Let us first import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/Applications/Anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ls', '../input']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5431bfc3e2c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msubprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/simon/Applications/Anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 336\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/simon/Applications/Anaconda3/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 418\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ls', '../input']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "color = sns.color_palette()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"Train shape : \", train_df.shape)\n",
    "print(\"Test shape : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow the number of rows are small with 388 columns. We should try not to overfit :)\n",
    "\n",
    "Let us look at the top few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Variable:**\n",
    "\n",
    "\"y\" is the variable we need to predict. So let us do some analysis on this variable first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(range(train_df.shape[0]), np.sort(train_df.y.values))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a single data point is well above the rest. \n",
    "\n",
    "Now let us plot the distribution graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ulimit = 180\n",
    "train_df['y'].ix[train_df['y']>ulimit] = ulimit\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(train_df.y.values, bins=50, kde=False)\n",
    "plt.xlabel('y value', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us have a look at the data type of all the variables present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_df = train_df.dtypes.reset_index()\n",
    "dtype_df.columns = [\"Count\", \"Column Type\"]\n",
    "dtype_df.groupby(\"Column Type\").aggregate('count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So majority of the columns are integers with 8 categorical columns and 1 float column (target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_df.ix[:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X0 to X8 are the categorical columns.\n",
    "\n",
    "**Missing values:**\n",
    "\n",
    "Let us now check for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "missing_df = train_df.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df = missing_df.ix[missing_df['missing_count']>0]\n",
    "missing_df = missing_df.sort_values(by='missing_count')\n",
    "missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to see that there are no missing values in the dataset :) \n",
    "\n",
    "**Integer Columns Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_values_dict = {}\n",
    "for col in train_df.columns:\n",
    "    if col not in [\"ID\", \"y\", \"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "        unique_value = str(np.sort(train_df[col].unique()).tolist())\n",
    "        tlist = unique_values_dict.get(unique_value, [])\n",
    "        tlist.append(col)\n",
    "        unique_values_dict[unique_value] = tlist[:]\n",
    "for unique_val, columns in unique_values_dict.items():\n",
    "    print(\"Columns containing the unique values : \",unique_val)\n",
    "    print(columns)\n",
    "    print(\"--------------------------------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all the integer columns are binary with some columns have only one unique value 0. Possibly we could exclude those columns in our modeling activity.\n",
    "\n",
    "Now let us explore the categorical columns present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X0\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X1\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.stripplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X2\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X3\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X4\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X5\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X6\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"X8\"\n",
    "col_order = np.sort(train_df[var_name].unique()).tolist()\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=var_name, y='y', data=train_df, order=col_order)\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Variables:**\n",
    "\n",
    "Now we can look into the binary variables. There are quite a few of them as we have seen before. Let us start with getting the number of 0's and 1's in each of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_count_list = []\n",
    "one_count_list = []\n",
    "cols_list = unique_values_dict['[0, 1]']\n",
    "for col in cols_list:\n",
    "    zero_count_list.append((train_df[col]==0).sum())\n",
    "    one_count_list.append((train_df[col]==1).sum())\n",
    "\n",
    "N = len(cols_list)\n",
    "ind = np.arange(N)\n",
    "width = 0.35\n",
    "\n",
    "plt.figure(figsize=(6,100))\n",
    "p1 = plt.barh(ind, zero_count_list, width, color='red')\n",
    "p2 = plt.barh(ind, one_count_list, width, left=zero_count_list, color=\"blue\")\n",
    "plt.yticks(ind, cols_list)\n",
    "plt.legend((p1[0], p2[0]), ('Zero count', 'One Count'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us check the mean y value in each of the binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "zero_mean_list = []\n",
    "one_mean_list = []\n",
    "cols_list = unique_values_dict['[0, 1]']\n",
    "for col in cols_list:\n",
    "    zero_mean_list.append(train_df.ix[train_df[col]==0].y.mean())\n",
    "    one_mean_list.append(train_df.ix[train_df[col]==1].y.mean())\n",
    "\n",
    "new_df = pd.DataFrame({\"column_name\":cols_list+cols_list, \"value\":[0]*len(cols_list) + [1]*len(cols_list), \"y_mean\":zero_mean_list+one_mean_list})\n",
    "new_df = new_df.pivot('column_name', 'value', 'y_mean')\n",
    "\n",
    "plt.figure(figsize=(8,80))\n",
    "sns.heatmap(new_df)\n",
    "plt.title(\"Mean of y value across binary variables\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary variables which shows a good color difference in the above graphs between 0 and 1 are likely to be more predictive given the the count distribution is also good between both the classes (can be seen from the previous graph). We will dive more into the important variables in the later part of the notebook.\n",
    "\n",
    "**ID variable:**\n",
    "\n",
    "One more important thing we need to look at it is ID variable. This will give an idea of how the splits are done across train and test (random or id based) and also to help see if ID has some potential prediction capability (probably not so useful for business)\n",
    "\n",
    "Let us first see how the 'y' variable changes with ID variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "var_name = \"ID\"\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.regplot(x=var_name, y='y', data=train_df, scatter_kws={'alpha':0.5, 's':30})\n",
    "plt.xlabel(var_name, fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of y variable with \"+var_name, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a slight decreasing trend with respect to ID variable. Now let us see how the IDs are distributed across train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,10))\n",
    "train_df['eval_set'] = \"train\"\n",
    "test_df['eval_set'] = \"test\"\n",
    "full_df = pd.concat([train_df[[\"ID\",\"eval_set\"]], test_df[[\"ID\",\"eval_set\"]]], axis=0)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.violinplot(x=\"eval_set\", y='ID', data=full_df)\n",
    "plt.xlabel(\"eval_set\", fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title(\"Distribution of ID variable with evaluation set\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a random split of ID variable between train and test samples.\n",
    "\n",
    "**Important Variables:**\n",
    "\n",
    "Now let us run and xgboost model to get the important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for f in [\"X0\", \"X1\", \"X2\", \"X3\", \"X4\", \"X5\", \"X6\", \"X8\"]:\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train_df[f].values)) \n",
    "        train_df[f] = lbl.transform(list(train_df[f].values))\n",
    "        \n",
    "train_y = train_df['y'].values\n",
    "train_X = train_df.drop([\"ID\", \"y\", \"eval_set\"], axis=1)\n",
    "\n",
    "# Thanks to anokas for this #\n",
    "def xgb_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds)\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'silent': 1\n",
    "}\n",
    "dtrain = xgb.DMatrix(train_X, train_y, feature_names=train_X.columns.values)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=100, feval=xgb_r2_score, maximize=True)\n",
    "\n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical occupy the top spots followed by binary variables. \n",
    "\n",
    "Let us also build a Random Forest model and check the important variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "model = ensemble.RandomForestRegressor(n_estimators=200, max_depth=10, min_samples_leaf=4, max_features=0.2, n_jobs=-1, random_state=0)\n",
    "model.fit(train_X, train_y)\n",
    "feat_names = train_X.columns.values\n",
    "\n",
    "## plot the importances ##\n",
    "importances = model.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in model.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1][:20]\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(len(indices)), importances[indices], color=\"r\", align=\"center\")\n",
    "plt.xticks(range(len(indices)), feat_names[indices], rotation='vertical')\n",
    "plt.xlim([-1, len(indices)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a few differences in the important variables between xgboost and random forest. Not sure why though.!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More to come. Stay tuned.!**\n",
    "\n",
    "**Please upvote if you like it.!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
